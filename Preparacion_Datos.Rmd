---
title: "Preparación de los Datos"
output: 
  html_document:
    toc: TRUE
    toc_depth: 4
---
```{r, eval=FALSE, include=FALSE}
t<-Sys.time()
```

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(DT)
library(scales)
```

```{r Utils, message=FALSE, warning=FALSE}
source('02_Utils.R')
```


# Preparación de los datos 


## Selección de los datos 

Hasta el momento, se seleccionan todas las variables disponibles. Cabe destacar que las variables de nombre de artículo, nombre de categoría y nombre de tienda se conservan con fines de interpretabilidad y para el análisis exploratorio, pero no se utilizarán en el modelado de los datos. 

```{r}
datos_train<-readRDS('Datos_trad/train_trad.rds')
datos_items<-readRDS('Datos_trad/datos_items.rds')
shops<-readRDS('Datos_trad/shops.rds')
```

## Limpieza de datos

### Tipo de variables 

Hechamos un vistazo a la base de datos obtenida del proceso de exploración. 

```{r }

glimpse(datos_train)

```

La variable *date* no es reconocida como fecha y la variable *tiem_cnt_day* no es reconocida como entero. Se hacen estos cambios. 

```{r}
# Se cambia la variable date a formato fechay la variable item_cnt_day a formato entero 
datos_train<-datos_train%>%
  mutate(date=as.Date(date,format="%d.%m.%Y"),
         item_cnt_day=as.integer(item_cnt_day))%>%
  select(date,everything())
```



### Datos faltantes

Checamos si existen datos faltantes en el set de entrenamiento. 
```{r DatosFaltantes}
# Summary para detectar presencia de NA's
summary(datos_train)
```

No se tienen valores faltantes en el set de entrenamiento. 


### Valores únicos por variable. 

Se verifican los valores únicos por variable para ver si existen o bservaciones con errores o si vale la pena categorizar alguna variable. 


Para las variables *date*, *date_block_num*, *shop_id*, *item_id*, *item_name*,*item_category_id*, *item_category_name*, *shop_name* y *ID* no es necesario checar los valores únicos ya se son identificadores de fecha, tienda, categoría o artículo. 


Las variables que sí se deben revisar son *item_price* y *item_cnt_day*. 

#### Precio por artículo 

```{r}
length(unique(datos_train$item_price))
```

Para la variable *item_price* se tienen 19,993 precios únicos. Esto no es sorpresa ya que la variable es de tipo double. Veamos un summary de esta variable para poder decidir sobre su distribución y posible categorización. 

```{r}
summary(datos_train$item_price)
```

En primer lugar, se puede notar que existen precios negativos, lo cual no es factible. En segundo lugar la diferencia entre el tercer cuantil y el máximo es muy grande, esto es señal de un dato atípico. 


Veamos los 20 valores más grandes del precio de los artículos.

```{r OutlierPrice}
head(sort(datos_train$item_price,decreasing = TRUE),20)
```

Efectivamente se trata de un valor atípico. Veamos de qué producto se trata. 
```{r OutlierPrice2}

datos_train$item_name[which(datos_train$item_price==307980)]
```

Investigando en 1C y, asumiendo que el precio está en dólares, se llegó a la conclusión de que se escribó mal el precio de este artículo y sería razonable pensar que el verdadero precio es de $3,079.80 dólares. Por lo tanto, se sustitye dico valor. 

```{r}
datos_train$item_price[which(datos_train$item_price==307980)]<-3079.80
```


En cuanto a los precios negativos, veamos cuantos son. 

```{r}
length(which(datos_train$item_price<0))
```

Sólo se tiene un artículo que tiene precio negativo. Busquemos si en la misma fecha se vendió el mismo artículo para extraer el verdadero precio. 

```{r NegPrice, warning=FALSE, message=FALSE}
# extraemos los items devueltos
item_id_pneg<-datos_train%>%
  filter(item_price<0)%>%
  select(item_id)%>%
  unique()%>%
  as.numeric

# extraemos la fecha de devolucion
date_pneg<-datos_train%>%
  filter(item_price<0)%>%
  select(date)%>%
  unique()

# Extraemso el precio promedio del objeto en la misma fecha
items_ppos<-datos_train%>%
  filter(item_id==item_id_pneg)%>%
  filter(date==date_pneg)%>%
  filter(item_price!=-1)%>%
  select(date, item_name, item_price)

datatable(items_ppos)

```

Se tienen otros tres articulos iguales vendidos en la misma fecha. Por lo tanto se reemplaza el precio negativo con el promedio del precio de estos artículos. 

```{r}
datos_train$item_price[which(datos_train$item_price==-1)]<-mean(items_ppos$item_price)  
summary(datos_train$item_price)
```

```{r}
ggplot(datos_train,aes(item_price))+
  geom_histogram(binwidth = 1000)+
  ggtitle('Item Price Distirbution')+
  xlab('Item Price')+
  ylab('Count')
  
```

Todavía existe una gran diferencia entre el tercer cuantil y el valor máximo del precio. Sin embargo, dado aue la tarea es predecir el número de articulos vendido cada mes de cada tipo en cada tienda, por el momento, no se realiza ninguna estrategia de categorización del precio. De ser necesario, se realizará en la parte de ingeniería de características. 


#### Número de unidades vendidas/devueltas. 

Verificamos los valores únicos para la variable *item_cnt_day*. 

```{r}
sort(unique(datos_train$item_cnt_day),decreasing = TRUE)
```

El número de unidades vendidas por artículo va desde 1 hasta 2169. El número de unidades devueltas por artículo va desde 1 hasta 22. No parece haber nada incorrecto en esta variable. 

Veamos que artículos fueron los más vendidos. 

```{r}
cnt_day_mayores<-sort(unique(datos_train$item_cnt_day),decreasing = TRUE)[1:10]

datos_train$item_name[match(cnt_day_mayores,datos_train$item_cnt_day)]
```
 
Al parecer, "Delivery to the point of delivery (Boxberry)" y "Ticket &quot;IgroMir 2015&quot; - October 3, 2015 (website) [Digital version]" son de los artículos más devueltos. 


# Feature Engineering

Para hacer el feature engineering nos olivdamos momentaneamente de los nombres de los artículos, categorías y tiendas y sólo trabajamos con el identificador de la tienda y del artículo, la fecha, el consecutivo de la fecha, el precio y las ventas. 

## Separar día mes y año 

De la variable *date* se puede separar el día, mes y año. Esto será de utilidad para los agregados mensuales. 

```{r}
datos_train<-datos_train%>%
  dplyr::select(date,date_block_num,shop_id,item_id,item_price,item_cnt_day)%>%
  mutate(day=as.integer(substring(as.character(date),9,10)),
         month=as.integer(substring(as.character(date),6,7)),
         year=as.integer(substring(as.character(date),1,4)))%>%
  select(date,day,month,year,everything())

head(datos_train)
```


```{r}
unique(datos_train$year)
```

La base de datos de entrenamiento tiene información diaria para tres años: 2013-2015. 


## Agregados Mensuales

La tarea es predecir las ventas mensuales por dupla (tienda, artículo); por lo tanto, se hace un agregado mensual de las variables. 


Para el número de artículos la suma de todos los artículos vendidos en el mismo mes. Para el precio del artículo se crean distintas medidas de agregación: máxmo, mínimo, media, mediana, moda y rango.


```{r AgregadoMensual, cache=TRUE}

# hacemos el agregado mensual por dupla (tienda,art) y fecha mensual (date_block_num)
train_mensuales<-datos_train%>%
  group_by(date_block_num,shop_id,item_id)%>%
  summarise(month=unique(month),
            year=unique(year),
            item_price_mean=mean(item_price),
            item_cnt_month=sum(item_cnt_day))

# Ordenaos por dupla 
train_mensuales<-arrange(train_mensuales,date_block_num,shop_id,item_id)

# guardar datos
saveRDS(train_mensuales,"Datos_clean/train_mensuales.rds")

```

Hechamos un vistazo a los datos mensuales
```{r}
glimpse(train_mensuales)
```

Un problema es que hay duplas (tienda, artículo) para las cuales no hay registro en algunos meses. Es decir, no en todos los meses del año se vendieron todos los artículos en todas las tiendas. Por lo tanto, no se tienen las series de tiempo completas por lo que hay que completarlas de tal manera que el algoritmo sea capaz de aprender estas irregularidades en las ventas. 

## Completar series de tiempo por dupla (tienda, artículo)

Creamos el grid con todas las posibles combinaciones por mes, tienda y artículo. 

```{r}
#Creamos grid de date_block_num, shop_id, item_id
train_mensuales_completo<-list(date_block_num=0:33,
                     shop_id=unique(shops$shop_id),
                     item_id=unique(datos_items$item_id))%>%
  expand.grid

dim(train_mensuales_completo)

```

Hacemos un merge de los datos mensuales observados obtenidos en el paso anterior con este grid. 

```{r}
# Hacemos left join de los datos mensuales 
train_mensuales_completo<-left_join(train_mensuales_completo,train_mensuales,by=c('date_block_num','shop_id','item_id'))
```

```{r}
glimpse(train_mensuales_completo)
```

```{r}
train_mensuales_completo<-train_mensuales_completo%>%
  left_join(datos_items,key='item_id')%>%
  left_join(shops,key='shop_id')
```

```{r}
glimpse(train_mensuales_completo)
```

Unicamente tenemos missings en item_price_mean y item_cnt_month. Los missings en item_cnt_ month corresponden a que no hubo ventas para ese artículo en ese mes en esa tienda; porlo tanto, sustituimos estos NA's con 0.

```{r}
train_mensuales_completo$item_cnt_month[which(is.na(train_mensuales_completo$item_cnt_month))]<-0
```

Para arreglar los NA's del precio, hacemos nuevas variables. Calculamos el precio promedio por artículo, el precio promedio de todos los artículos en cada categorìa y el precio promedio de todos los artículos en cada tienda. 

```{r}

# Por artículo
mean_price_item<-train_mensuales_completo%>%
  group_by(item_id)%>%
  summarise(item_price_mean_art=mean(item_price_mean,na.rm=TRUE),
            item_cnt_art=sum(item_cnt_month),
            item_cnt_mean_art=mean(item_cnt_month,na.rm=TRUE))


# Por categoria
mean_price_cat<-train_mensuales_completo%>%
  group_by(item_category_id)%>%
  summarise(item_price_mean_cat=mean(item_price_mean,na.rm=TRUE),
            item_cnt_cat=sum(item_cnt_month),
            item_cnt_mean_cat=mean(item_cnt_month,na.rm=TRUE))

# Por tienda
mean_price_shop<-train_mensuales_completo%>%
  group_by(shop_id)%>%
  summarise(item_price_mean_shop=mean(item_price_mean,na.rm=TRUE),
            item_cnt_shop=sum(item_cnt_month),
            item_cnt_mean_shop=mean(item_cnt_month,na.rm=TRUE))
```

Ahora hacemos un left join de estos nuevos precios con el data set completo 

```{r}
# Juntamos los distintos precios 
train_mensuales_completo<-train_mensuales_completo%>%
  left_join(mean_price_item, key='item_id')%>%
  left_join(mean_price_cat, key='item_category_id')%>%
  left_join(mean_price_shop,key='shop_id')

rm(mean_price_item,mean_price_cat,mean_price_shop)
```

```{r}
glimpse(train_mensuales_completo)
```

```{r}
summary(train_mensuales_completo)
```

Ya solo tenemos NA's en el precio promedio original y en el precio promedio por artículo. El primero no se va a utilizar ya que sólo sirvió para construir el resto de las características. En cuanto al segundo, se imputa con la mediana debido a la existencia de datos atípicos en el precio. 

```{r}
train_mensuales_completo<-train_mensuales_completo%>%
  dplyr::select(-item_price_mean)

train_mensuales_completo$item_price_mean_art[which(is.na(train_mensuales_completo$item_price_mean_art))]<-median(train_mensuales_completo$item_price_mean_art,na.rm=TRUE)
```

## Rezagos de las variables 

Dado que en la verdadera tarea de predicción no se van a tener los datos actuales, sino los datos de los meses previos, creamos rezagos de las variables actuales: mensual, bimestral, trimestral, semestral. 

```{r}
# mem_change(rm(train_mensuales))

# # guardar datos
saveRDS(train_mensuales_completo,"Datos_clean/train_mensuales_completo.rds")
write_csv(train_mensuales_completo,"Datos_clean/train_mensuales_completo.csv")

train_mensuales_completo<-train_mensuales_completo%>%
  mutate(item_price_mean_art_l1=lag(item_price_mean_art),
         item_price_mean_art_l2=lag(item_price_mean_art,2),
         item_price_mean_art_l3=lag(item_price_mean_art,3),
         item_price_mean_art_l6=lag(item_price_mean_art,6),
         item_cnt_art_l1=lag(item_cnt_art),
         item_cnt_art_l2=lag(item_cnt_art,2),
         item_cnt_art_l3=lag(item_cnt_art,3),
         item_cnt_art_l6=lag(item_cnt_art,6),
         item_cnt_mean_art_l1=lag(item_cnt_mean_art),
         item_cnt_mean_art_l2=lag(item_cnt_mean_art,2),
         item_cnt_mean_art_l3=lag(item_cnt_mean_art,3),
         item_cnt_mean_art_l6=lag(item_cnt_mean_art,6),
         item_price_mean_cat_l1=lag(item_price_mean_cat),
         item_price_mean_cat_l2=lag(item_price_mean_cat,2),
         item_price_mean_cat_l3=lag(item_price_mean_cat,3),
         item_price_mean_cat_l6=lag(item_price_mean_cat,6),
         item_cnt_cat_l1=lag(item_cnt_cat),
         item_cnt_cat_l2=lag(item_cnt_cat,2),
         item_cnt_cat_l3=lag(item_cnt_cat,3),
         item_cnt_cat_l6=lag(item_cnt_cat,6),
         item_cnt_mean_art_l1=lag(item_cnt_mean_art),
         item_cnt_mean_art_l2=lag(item_cnt_mean_art,2),
         item_cnt_mean_art_l3=lag(item_cnt_mean_art,3),
         item_cnt_mean_art_l6=lag(item_cnt_mean_art,6),
         item_price_mean_shop_l1=lag(item_price_mean_shop),
         item_price_mean_shop_l2=lag(item_price_mean_shop,2),
         item_price_mean_shop_l3=lag(item_price_mean_shop,3),
         item_price_mean_shop_l6=lag(item_price_mean_shop,6),
         item_cnt_shop_l1=lag(item_cnt_shop),
         item_cnt_shop_l2=lag(item_cnt_shop,2),
         item_cnt_shop_l3=lag(item_cnt_shop,3),
         item_cnt_shop_l6=lag(item_cnt_shop,6),
         item_cnt_mean_shop_l1=lag(item_cnt_mean_shop),
         item_cnt_mean_shop_l2=lag(item_cnt_mean_shop,2),
         item_cnt_mean_shop_l3=lag(item_cnt_mean_shop,3),
         item_cnt_mean_shop_l6=lag(item_cnt_mean_shop,6))
# 
# # guardar datos
# saveRDS(train_mensuales_completo,"Datos_clean/train_mensuales_completo.rds")

```


```{r}
# mem_change(rm(train_mensuales))

# # guardar datos
saveRDS(train_mensuales_completo,"Datos_clean/train_mensuales_completo.rds")

train_mensuales_completo<-train_mensuales_completo%>%
  mutate(item_price_mean_art_l1=lag(item_price_mean_art),
         item_price_mean_art_l2=lag(item_price_mean_art,2),
         item_price_mean_art_l3=lag(item_price_mean_art,3),
         item_price_mean_art_l6=lag(item_price_mean_art,6),
         item_cnt_art_l1=lag(item_cnt_art),
         item_cnt_art_l2=lag(item_cnt_art,2),
         item_cnt_art_l3=lag(item_cnt_art,3),
         item_cnt_art_l6=lag(item_cnt_art,6),
         item_cnt_mean_art_l1=lag(item_cnt_mean_art),
         item_cnt_mean_art_l2=lag(item_cnt_mean_art,2),
         item_cnt_mean_art_l3=lag(item_cnt_mean_art,3),
         item_cnt_mean_art_l6=lag(item_cnt_mean_art,6),
         item_cnt_mean_art_l12=lag(item_cnt_mean_art,12))

saveRDS(train_mensuales_completo,"Datos_clean/train_mensuales_completo.rds")


mem_change(rm(train_mensuales_completo))

train_mensuales_completo<-readRDS("Datos_clean/train_mensuales_completo.rds")

# train_mensuales_completo<-train_mensuales_completo%>%
#   mutate(  item_price_mean_cat_l1=lag(item_price_mean_cat),
#          item_price_mean_cat_l2=lag(item_price_mean_cat,2),
#          item_price_mean_cat_l3=lag(item_price_mean_cat,3),
#          item_price_mean_cat_l6=lag(item_price_mean_cat,6),
#          item_cnt_cat_l1=lag(item_cnt_cat),
#          item_cnt_cat_l2=lag(item_cnt_cat,2),
#          item_cnt_cat_l3=lag(item_cnt_cat,3),
#          item_cnt_cat_l6=lag(item_cnt_cat,6),
#          item_cnt_mean_art_l1=lag(item_cnt_mean_art),
#          item_cnt_mean_art_l2=lag(item_cnt_mean_art,2),
#          item_cnt_mean_art_l3=lag(item_cnt_mean_art,3),
#          item_cnt_mean_art_l6=lag(item_cnt_mean_art,6),
#          item_price_mean_shop_l1=lag(item_price_mean_shop),
#          item_price_mean_shop_l2=lag(item_price_mean_shop,2),
#          item_price_mean_shop_l3=lag(item_price_mean_shop,3),
#          item_price_mean_shop_l6=lag(item_price_mean_shop,6),
#          item_cnt_shop_l1=lag(item_cnt_shop),
#          item_cnt_shop_l2=lag(item_cnt_shop,2),
#          item_cnt_shop_l3=lag(item_cnt_shop,3),
#          item_cnt_shop_l6=lag(item_cnt_shop,6),
#          item_cnt_mean_shop_l1=lag(item_cnt_mean_shop),
#          item_cnt_mean_shop_l2=lag(item_cnt_mean_shop,2),
#          item_cnt_mean_shop_l3=lag(item_cnt_mean_shop,3),
#          item_cnt_mean_shop_l6=lag(item_cnt_mean_shop,6))
# 
# # guardar datos
# saveRDS(train_mensuales_completo,"Datos_clean/train_mensuales_completo.rds")

```

<!-- Imputamos los NA's de los rezagos con el primer valor observado.  -->

<!-- ```{r} -->
<!-- aux<-train_mensuales_completo%>% -->
<!--   dplyr::select(contains("l1"))%>% -->
<!--   dplyr::select(-contains("l12")) -->
<!-- ``` -->


<!-- ## Escalamiento del número de artículos vendidos -->

<!-- Para efectos de la competencia en Kaggle, el número de artículos vendidos debe estar entre 0 y 20. Por lo tanto se escala la variable *item_cnt_month* -->

<!-- ```{r, eval=FALSE, include=FALSE} -->
<!-- train_mensuales$item_cnt_month_rescale<-rescale(train_mensuales$item_cnt_month,to=c(0,20)) -->
<!-- ``` -->


<!-- # Almacenamiento de los datos  -->

<!-- Almacenamos los datos mensuales de las ventas limpios en el objeto **train_mensuales.rds**.  -->

<!-- ```{r SaveCleanData,eval=FALSE, include=FALSE} -->
<!-- # Guardamos como objeto Rds  -->
<!-- saveRDS(train_mensuales,"Datos_clean/train_mensuales.rds") -->
<!-- ``` -->

<!-- ```{r, eval=FALSE, include=FALSE} -->
<!-- t<-t-Sys.time() -->

<!-- t -->
<!-- ``` -->